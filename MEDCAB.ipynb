{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import squarify\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "from spacy.tokenizer import Tokenizer\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./final_df_percentsep.csv', sep='%', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>flavors</th>\n",
       "      <th>race</th>\n",
       "      <th>positive_effects</th>\n",
       "      <th>negative_effects</th>\n",
       "      <th>medical_uses</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afpak</td>\n",
       "      <td>Earthy, Chemical, Pine, SpicyHerbal</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>Relaxed, Hungry, Happy, Sleepy, Creative, Focused</td>\n",
       "      <td>Dizzy</td>\n",
       "      <td>Depression, Insomnia, Pain, Stress, Lack of Ap...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Afpak named for its direct Afghani and Pakista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>African</td>\n",
       "      <td>SpicyHerbal, Pungent, Earthy, Pepper</td>\n",
       "      <td>sativa</td>\n",
       "      <td>Euphoric, Happy, Creative, Energetic, Talkativ...</td>\n",
       "      <td>Dry Mouth</td>\n",
       "      <td>Depression, Pain, Stress, Lack of Appetite, Na...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>African refers to the indigenous varieties of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afternoon Delight</td>\n",
       "      <td>Pepper, Flowery, Pine, Pungent, Citrus, Tropical</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>Relaxed, Hungry, Euphoric, Uplifted, Tingly, T...</td>\n",
       "      <td>Dizzy, Dry Mouth, Paranoid</td>\n",
       "      <td>Depression, Insomnia, Pain, Stress, Cramps, He...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Afternoon Delight created by Colorado Seed Inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afwreck</td>\n",
       "      <td>Pine, Earthy, Flowery, Pungent</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>Relaxed, Happy, Creative, Uplifted, Sleepy, Eu...</td>\n",
       "      <td>Dizzy, Dry Mouth, Paranoid, Dry Eyes</td>\n",
       "      <td>Pain, Stress, Headache, Fatigue, Headaches, Mu...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Afwreck is a hybrid cross of Afghani and Train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Agent Orange</td>\n",
       "      <td>Citrus, Orange, Sweet, Earthy</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>Relaxed, Euphoric, Happy, Energetic, Uplifted</td>\n",
       "      <td>Dizzy, Dry Mouth, Paranoid, Dry Eyes</td>\n",
       "      <td>Depression, Pain, Stress, Nausea, Headache, He...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Don’t let the name scare you! The only herbici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name                                           flavors  \\\n",
       "1              Afpak               Earthy, Chemical, Pine, SpicyHerbal   \n",
       "2            African              SpicyHerbal, Pungent, Earthy, Pepper   \n",
       "3  Afternoon Delight  Pepper, Flowery, Pine, Pungent, Citrus, Tropical   \n",
       "4            Afwreck                    Pine, Earthy, Flowery, Pungent   \n",
       "5       Agent Orange                     Citrus, Orange, Sweet, Earthy   \n",
       "\n",
       "     race                                   positive_effects  \\\n",
       "1  hybrid  Relaxed, Hungry, Happy, Sleepy, Creative, Focused   \n",
       "2  sativa  Euphoric, Happy, Creative, Energetic, Talkativ...   \n",
       "3  hybrid  Relaxed, Hungry, Euphoric, Uplifted, Tingly, T...   \n",
       "4  hybrid  Relaxed, Happy, Creative, Uplifted, Sleepy, Eu...   \n",
       "5  hybrid      Relaxed, Euphoric, Happy, Energetic, Uplifted   \n",
       "\n",
       "                       negative_effects  \\\n",
       "1                                 Dizzy   \n",
       "2                             Dry Mouth   \n",
       "3            Dizzy, Dry Mouth, Paranoid   \n",
       "4  Dizzy, Dry Mouth, Paranoid, Dry Eyes   \n",
       "5  Dizzy, Dry Mouth, Paranoid, Dry Eyes   \n",
       "\n",
       "                                        medical_uses  Rating  \\\n",
       "1  Depression, Insomnia, Pain, Stress, Lack of Ap...     4.2   \n",
       "2  Depression, Pain, Stress, Lack of Appetite, Na...     3.9   \n",
       "3  Depression, Insomnia, Pain, Stress, Cramps, He...     4.8   \n",
       "4  Pain, Stress, Headache, Fatigue, Headaches, Mu...     4.2   \n",
       "5  Depression, Pain, Stress, Nausea, Headache, He...     4.2   \n",
       "\n",
       "                                         Description  \n",
       "1  Afpak named for its direct Afghani and Pakista...  \n",
       "2  African refers to the indigenous varieties of ...  \n",
       "3  Afternoon Delight created by Colorado Seed Inc...  \n",
       "4  Afwreck is a hybrid cross of Afghani and Train...  \n",
       "5  Don’t let the name scare you! The only herbici...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna('none')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                0\n",
       "flavors             0\n",
       "race                0\n",
       "positive_effects    0\n",
       "negative_effects    0\n",
       "medical_uses        0\n",
       "Rating              0\n",
       "Description         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all text features into one string:\n",
    "\n",
    "df['combined_text'] = df.name + \" \" + df.flavors +  \" \" + df.race + \" \" + df.positive_effects + \" \" + df.negative_effects + \" \" + df.medical_uses + \" \" + df.Description\n",
    "# Removing punctuations from our string\n",
    "df[\"combined_text\"] = df['combined_text'].str.replace('[^\\w\\s]',' ')\n",
    "df[\"combined_text\"] = df['combined_text'].str.replace('none','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "\n",
    "STOP_WORDS = nlp.Defaults.stop_words.union([' ','  ', '-PRON-', 'none'])\n",
    "\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df['combined_text'], batch_size=500):\n",
    "    \n",
    "    doc_tokens = []\n",
    "    \n",
    "    for token in doc: \n",
    "        if token.text.lower() not in STOP_WORDS:\n",
    "            doc_tokens.append(token.text.lower())\n",
    "   \n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       [afpak, earthy, chemical, pine, spicyherbal, h...\n",
       "2       [african, spicyherbal, pungent, earthy, pepper...\n",
       "3       [afternoon, delight, pepper, flowery, pine, pu...\n",
       "4       [afwreck, pine, earthy, flowery, pungent, hybr...\n",
       "5       [agent, orange, citrus, orange, sweet, earthy,...\n",
       "                              ...                        \n",
       "1459    [yummy, sweet, earthy, pungent, hybrid, relaxe...\n",
       "1460    [zen, earthy, woody, flowery, sweet, hybrid, r...\n",
       "1461    [zeta, sage, sage, diesel, sweet, pungent, sat...\n",
       "1462    [zkittlez, sweet, berry, grape, indica, relaxe...\n",
       "1463    [zoom, pie, berry, earthy, pungent, indica, re...\n",
       "Name: tokens, Length: 1463, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmas'] = df['combined_text'].apply(lambda text: [token.lemma_ for token in nlp(text) if (token.is_stop != True) and (token.is_punct != True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       Afpak Earthy   Chemical   Pine   SpicyHerbal h...\n",
       "2       African SpicyHerbal   pungent   Earthy   Peppe...\n",
       "3       afternoon Delight Pepper   flowery   Pine   pu...\n",
       "4       Afwreck Pine   Earthy   Flowery   pungent hybr...\n",
       "5       Agent Orange Citrus   Orange   sweet   earthy ...\n",
       "                              ...                        \n",
       "1459    yummy Sweet   Earthy   pungent hybrid relaxed ...\n",
       "1460    Zen Earthy   Woody   Flowery   sweet hybrid re...\n",
       "1461    Zeta Sage Sage   diesel   sweet   pungent sati...\n",
       "1462    Zkittlez Sweet   Berry   Grape indica relaxed ...\n",
       "1463    zoom pie berry   Earthy   pungent indica relax...\n",
       "Name: lemmas, Length: 1463, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmas'] = df['lemmas'].str.join(' ')\n",
    "df['lemmas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>1974</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>47</th>\n",
       "      <th>51</th>\n",
       "      <th>69</th>\n",
       "      <th>91</th>\n",
       "      <th>...</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zinger</th>\n",
       "      <th>zion</th>\n",
       "      <th>zip</th>\n",
       "      <th>zkittlez</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5557 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    11   12   13  1974   43   44   47   51   69   91  ...  zesty  zeta  \\\n",
       "0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "1  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "2  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "3  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "4  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "\n",
       "   zinger  zion  zip  zkittlez  zombie  zombies  zone  zoom  \n",
       "0     0.0   0.0  0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "1     0.0   0.0  0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "2     0.0   0.0  0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "3     0.0   0.0  0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "4     0.0   0.0  0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 5557 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "dtm3 = tfidf.fit_transform(df['lemmas'])\n",
    "dtm3 = pd.DataFrame(dtm3.todense(), columns=tfidf.get_feature_names())\n",
    "dtm3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on DTM\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "nn.fit(dtm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'todense'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b58ca71bee99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommended_strains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/MEDCAB/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5272\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5273\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'todense'"
     ]
    }
   ],
   "source": [
    "# with putting it back into a df:\n",
    "test_input = [\"I need something to help with anxiety and pain but has a sweet flavor\"]\n",
    "user_input = tfidf.transform(test_input)\n",
    "input_df = pd.DataFrame(user_input.todense())\n",
    "score, recommended_strains = nn.kneighbors(input_df.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without putting it back into a df:\n",
    "user_input = \"I want something to help with lack of appetite\"\n",
    "user_input = pd.Series(user_input)\n",
    "vect_input = tfidf.transform(user_input)\n",
    "score, recommended_strains = nn.kneighbors(vect_input.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1213, 1079, 361, 712, 857]\n"
     ]
    }
   ],
   "source": [
    "print(strain_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2646706  1.28472022 1.30472906 1.31082991 1.31861087]] [[1448 1281 1148  620   77]]\n"
     ]
    }
   ],
   "source": [
    "print(score, recommended_strains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test without lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=50, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without lemmatization & putting into dataframe\n",
    "dtm2 = tfidf.fit_transform(df['combined_text'])\n",
    "dtm2 = pd.DataFrame(dtm2.todense(), columns=tfidf.get_feature_names())\n",
    "# Fit on DTM\n",
    "nn = NearestNeighbors(n_neighbors=5, leaf_size=50, algorithm='kd_tree')\n",
    "nn.fit(dtm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.30060439 1.30612465 1.30721683 1.31698194 1.33486556]] [[1309  779  272  530  783]]\n"
     ]
    }
   ],
   "source": [
    "test_input = [\"Looking for something to help with headaches\"]\n",
    "user_input = tfidf.transform(test_input)\n",
    "score, strain_index = nn.kneighbors(user_input.todense())\n",
    "print(score, strain_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                name                                       medical_uses\n",
      "1309  Tangerine Haze  Depression, Pain, Stress, Headache, Fatigue, E...\n",
      "779     Killer Queen  Depression, Pain, Stress, Nausea, Headache, Fa...\n",
      "272        Candyland       Depression, Pain, Stress, Fatigue, Headaches\n",
      "530      Fruit Loops      Depression, Insomnia, Pain, Stress, Headaches\n",
      "783        King Kong  Depression, Insomnia, Pain, Stress, Muscle Spasms]\n"
     ]
    }
   ],
   "source": [
    "strains = [df[['name', 'medical_uses']].loc[n] for n in strain_index]\n",
    "print(strains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Basilica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import basilica\n",
    "API_KEY = '6b4eb009-61ef-5937-b4e6-444e5c3acc85'\n",
    "with basilica.Connection(API_KEY) as c:\n",
    "    embedded = []\n",
    "    for row in df['combined_text']:\n",
    "        sentence = row\n",
    "        embedding = list(c.embed_sentence(sentence))\n",
    "        embedded.append(embedding)\n",
    "    df['embedded'] = embedded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>flavors</th>\n",
       "      <th>race</th>\n",
       "      <th>positive_effects</th>\n",
       "      <th>negative_effects</th>\n",
       "      <th>medical_uses</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>embedded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afpak</td>\n",
       "      <td>Earthy, Chemical, Pine, SpicyHerbal</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>Relaxed, Hungry, Happy, Sleepy, Creative, Focused</td>\n",
       "      <td>Dizzy</td>\n",
       "      <td>Depression, Insomnia, Pain, Stress, Lack of Ap...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Afpak named for its direct Afghani and Pakista...</td>\n",
       "      <td>Afpak Earthy  Chemical  Pine  SpicyHerbal hybr...</td>\n",
       "      <td>[afpak, earthy, chemical, pine, spicyherbal, h...</td>\n",
       "      <td>Afpak Earthy   Chemical   Pine   SpicyHerbal h...</td>\n",
       "      <td>[0.0285604, -0.341568, 0.219712, -0.127979, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>African</td>\n",
       "      <td>SpicyHerbal, Pungent, Earthy, Pepper</td>\n",
       "      <td>sativa</td>\n",
       "      <td>Euphoric, Happy, Creative, Energetic, Talkativ...</td>\n",
       "      <td>Dry Mouth</td>\n",
       "      <td>Depression, Pain, Stress, Lack of Appetite, Na...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>African refers to the indigenous varieties of ...</td>\n",
       "      <td>African SpicyHerbal  Pungent  Earthy  Pepper s...</td>\n",
       "      <td>[african, spicyherbal, pungent, earthy, pepper...</td>\n",
       "      <td>African SpicyHerbal   pungent   Earthy   Peppe...</td>\n",
       "      <td>[0.00377018, 0.114895, 0.159532, -0.232496, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afternoon Delight</td>\n",
       "      <td>Pepper, Flowery, Pine, Pungent, Citrus, Tropical</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>Relaxed, Hungry, Euphoric, Uplifted, Tingly, T...</td>\n",
       "      <td>Dizzy, Dry Mouth, Paranoid</td>\n",
       "      <td>Depression, Insomnia, Pain, Stress, Cramps, He...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Afternoon Delight created by Colorado Seed Inc...</td>\n",
       "      <td>Afternoon Delight Pepper  Flowery  Pine  Punge...</td>\n",
       "      <td>[afternoon, delight, pepper, flowery, pine, pu...</td>\n",
       "      <td>afternoon Delight Pepper   flowery   Pine   pu...</td>\n",
       "      <td>[-0.0594041, -0.401205, 0.0903683, -0.143796, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afwreck</td>\n",
       "      <td>Pine, Earthy, Flowery, Pungent</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>Relaxed, Happy, Creative, Uplifted, Sleepy, Eu...</td>\n",
       "      <td>Dizzy, Dry Mouth, Paranoid, Dry Eyes</td>\n",
       "      <td>Pain, Stress, Headache, Fatigue, Headaches, Mu...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Afwreck is a hybrid cross of Afghani and Train...</td>\n",
       "      <td>Afwreck Pine  Earthy  Flowery  Pungent hybrid ...</td>\n",
       "      <td>[afwreck, pine, earthy, flowery, pungent, hybr...</td>\n",
       "      <td>Afwreck Pine   Earthy   Flowery   pungent hybr...</td>\n",
       "      <td>[-0.21463, -0.12518, 0.580927, -0.130724, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Agent Orange</td>\n",
       "      <td>Citrus, Orange, Sweet, Earthy</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>Relaxed, Euphoric, Happy, Energetic, Uplifted</td>\n",
       "      <td>Dizzy, Dry Mouth, Paranoid, Dry Eyes</td>\n",
       "      <td>Depression, Pain, Stress, Nausea, Headache, He...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Don’t let the name scare you! The only herbici...</td>\n",
       "      <td>Agent Orange Citrus  Orange  Sweet  Earthy hyb...</td>\n",
       "      <td>[agent, orange, citrus, orange, sweet, earthy,...</td>\n",
       "      <td>Agent Orange Citrus   Orange   sweet   earthy ...</td>\n",
       "      <td>[-0.0601283, -0.061624, 0.275476, 0.0656168, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name                                           flavors  \\\n",
       "1              Afpak               Earthy, Chemical, Pine, SpicyHerbal   \n",
       "2            African              SpicyHerbal, Pungent, Earthy, Pepper   \n",
       "3  Afternoon Delight  Pepper, Flowery, Pine, Pungent, Citrus, Tropical   \n",
       "4            Afwreck                    Pine, Earthy, Flowery, Pungent   \n",
       "5       Agent Orange                     Citrus, Orange, Sweet, Earthy   \n",
       "\n",
       "     race                                   positive_effects  \\\n",
       "1  hybrid  Relaxed, Hungry, Happy, Sleepy, Creative, Focused   \n",
       "2  sativa  Euphoric, Happy, Creative, Energetic, Talkativ...   \n",
       "3  hybrid  Relaxed, Hungry, Euphoric, Uplifted, Tingly, T...   \n",
       "4  hybrid  Relaxed, Happy, Creative, Uplifted, Sleepy, Eu...   \n",
       "5  hybrid      Relaxed, Euphoric, Happy, Energetic, Uplifted   \n",
       "\n",
       "                       negative_effects  \\\n",
       "1                                 Dizzy   \n",
       "2                             Dry Mouth   \n",
       "3            Dizzy, Dry Mouth, Paranoid   \n",
       "4  Dizzy, Dry Mouth, Paranoid, Dry Eyes   \n",
       "5  Dizzy, Dry Mouth, Paranoid, Dry Eyes   \n",
       "\n",
       "                                        medical_uses  Rating  \\\n",
       "1  Depression, Insomnia, Pain, Stress, Lack of Ap...     4.2   \n",
       "2  Depression, Pain, Stress, Lack of Appetite, Na...     3.9   \n",
       "3  Depression, Insomnia, Pain, Stress, Cramps, He...     4.8   \n",
       "4  Pain, Stress, Headache, Fatigue, Headaches, Mu...     4.2   \n",
       "5  Depression, Pain, Stress, Nausea, Headache, He...     4.2   \n",
       "\n",
       "                                         Description  \\\n",
       "1  Afpak named for its direct Afghani and Pakista...   \n",
       "2  African refers to the indigenous varieties of ...   \n",
       "3  Afternoon Delight created by Colorado Seed Inc...   \n",
       "4  Afwreck is a hybrid cross of Afghani and Train...   \n",
       "5  Don’t let the name scare you! The only herbici...   \n",
       "\n",
       "                                       combined_text  \\\n",
       "1  Afpak Earthy  Chemical  Pine  SpicyHerbal hybr...   \n",
       "2  African SpicyHerbal  Pungent  Earthy  Pepper s...   \n",
       "3  Afternoon Delight Pepper  Flowery  Pine  Punge...   \n",
       "4  Afwreck Pine  Earthy  Flowery  Pungent hybrid ...   \n",
       "5  Agent Orange Citrus  Orange  Sweet  Earthy hyb...   \n",
       "\n",
       "                                              tokens  \\\n",
       "1  [afpak, earthy, chemical, pine, spicyherbal, h...   \n",
       "2  [african, spicyherbal, pungent, earthy, pepper...   \n",
       "3  [afternoon, delight, pepper, flowery, pine, pu...   \n",
       "4  [afwreck, pine, earthy, flowery, pungent, hybr...   \n",
       "5  [agent, orange, citrus, orange, sweet, earthy,...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "1  Afpak Earthy   Chemical   Pine   SpicyHerbal h...   \n",
       "2  African SpicyHerbal   pungent   Earthy   Peppe...   \n",
       "3  afternoon Delight Pepper   flowery   Pine   pu...   \n",
       "4  Afwreck Pine   Earthy   Flowery   pungent hybr...   \n",
       "5  Agent Orange Citrus   Orange   sweet   earthy ...   \n",
       "\n",
       "                                            embedded  \n",
       "1  [0.0285604, -0.341568, 0.219712, -0.127979, -0...  \n",
       "2  [0.00377018, 0.114895, 0.159532, -0.232496, -0...  \n",
       "3  [-0.0594041, -0.401205, 0.0903683, -0.143796, ...  \n",
       "4  [-0.21463, -0.12518, 0.580927, -0.130724, -0.2...  \n",
       "5  [-0.0601283, -0.061624, 0.275476, 0.0656168, -...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('embedded_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import basilica\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sklearn.decomposition\n",
    "import sklearn.neighbors\n",
    "import sklearn.preprocessing\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1463, 75)\n"
     ]
    }
   ],
   "source": [
    "data_input = np.stack(df['embedded'].values, axis=0)\n",
    "\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler(with_std=False)\n",
    "pca = sklearn.decomposition.PCA(n_components=75, whiten=True)\n",
    "\n",
    "\n",
    "data_input = scaler.fit_transform(data_input)\n",
    "data_input = pca.fit_transform(data_input)\n",
    "data_input = sklearn.preprocessing.normalize(data_input)\n",
    "print(data_input.shape)\n",
    "\n",
    "dtm = pd.DataFrame(data_input)\n",
    "# Fit on DTM\n",
    "nn3 = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.07226059 1.09184254 1.09362405 1.11285674 1.1443225 ]] [[ 188 1075  272 1333  116]]\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I need something to help with anxiety and pain but has a sweet flavor\"\n",
    "with basilica.Connection(API_KEY) as c:\n",
    "    embedded = c.embed_sentence(user_input)\n",
    "\n",
    "embedded = np.stack([embedded], axis=0)\n",
    "\n",
    "user_input = scaler.transform(embedded)\n",
    "user_input = pca.transform(user_input)\n",
    "user_input = sklearn.preprocessing.normalize(user_input)\n",
    "\n",
    "score, strain_index = nn3.kneighbors(user_input)\n",
    "print(score, strain_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                    name                          flavors  \\\n",
      "1075        Purple Crack           Earthy, Pungent, Sweet   \n",
      "188   Blue Mountain Fire     Earthy, Flowery, Pepper, Tar   \n",
      "272            Candyland  Sweet, Earthy, Pungent, Flowery   \n",
      "1333             The One    Earthy, Pungent, Pine, Diesel   \n",
      "116    Black Cherry Soda             Sweet, Berry, Earthy   \n",
      "\n",
      "                                           medical_uses  \n",
      "1075      Depression, Insomnia, Pain, Stress, Headaches  \n",
      "188                                  Depression, Stress  \n",
      "272        Depression, Pain, Stress, Fatigue, Headaches  \n",
      "1333     Depression, Pain, Stress, Nausea, Inflammation  \n",
      "116   Depression, Pain, Stress, Headache, Fatigue, H...  ]\n"
     ]
    }
   ],
   "source": [
    "strains = [df[['name', 'flavors', 'medical_uses']].loc[n] for n in strain_index]\n",
    "print(strains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1463, 75)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input = np.stack(df['embedded'].values, axis=0)\n",
    "\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler(with_std=False)\n",
    "pca = sklearn.decomposition.PCA(n_components=75, whiten=True)\n",
    "normalizer = sklearn.preprocessing.Normalizer().fit(pcad)\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "\n",
    "scaled = scaler.fit_transform(data_input)\n",
    "print(type(scaled))\n",
    "pcad = pca.fit_transform(scaled)\n",
    "normd = sklearn.preprocessing.normalize(pcad)\n",
    "dtm = pd.DataFrame(normd)\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(dtm)\n",
    "\n",
    "\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normd.pkl']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'scaler.pkl') \n",
    "joblib.dump(pca, 'pcaer.pkl')\n",
    "joblib.dump(nn, 'nnmodel.pkl') \n",
    "joblib.dump(normalizer, 'normd.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('nn.pkl')\n",
    "scaled = joblib.load('scaler.pkl')\n",
    "pcaer = joblib.load('pcaer.pkl')\n",
    "nnmodel = joblib.load('nnmodel.pkl')\n",
    "normd = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "500 Server Error: Internal Server Error for url: https://api.basilica.ai/embed/text/english/default",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-cf5f827daf01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"I need something to help with anxiety and pain but has a sweet flavor\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mbasilica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPI_KEY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/MEDCAB/lib/python3.7/site-packages/basilica/__init__.py\u001b[0m in \u001b[0;36membed_sentence\u001b[0;34m(self, sentence, model, version, opts, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \"\"\"\n\u001b[1;32m    358\u001b[0m         return list(self.embed_sentences([sentence], model=model, version=version,\n\u001b[0;32m--> 359\u001b[0;31m                                          opts=opts, timeout=timeout))[0]\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__encode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/MEDCAB/lib/python3.7/site-packages/basilica/__init__.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, url, data, batch_size, opts, timeout)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0memb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DONE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/MEDCAB/lib/python3.7/site-packages/basilica/__init__.py\u001b[0m in \u001b[0;36mraw_embed_wrapper\u001b[0;34m(self, url, opts, timeout, batch_queue, emb_queue)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0memb_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DONE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0memb_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/MEDCAB/lib/python3.7/site-packages/basilica/__init__.py\u001b[0m in \u001b[0;36mraw_embed\u001b[0;34m(self, url, data, opts, timeout)\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/MEDCAB/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api.basilica.ai/embed/text/english/default"
     ]
    }
   ],
   "source": [
    "target = \"I need something to help with anxiety and pain but has a sweet flavor\"\n",
    "with basilica.Connection(API_KEY) as c:\n",
    "    embedded = c.embed_sentence(target)\n",
    "\n",
    "embedded = np.stack([embedded], axis=0)\n",
    "embedded.shape\n",
    "\n",
    "user_input = scaled.transform(embedded)\n",
    "user_input = pcaer.transform(user_input)\n",
    "\n",
    "# score, strain_index = nn3.kneighbors(embedded1)\n",
    "# print(score, strain_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessor.pkl']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaled, 'scaled.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn.pkl']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(nn, 'nn.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MEDCAB",
   "language": "python",
   "name": "medcab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
